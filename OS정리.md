# 프로세스

프로그램은 코드로서 저장장치에 존재한다.

이러한 코드가 운영체제로 부터 독립적인 메모리 영역(`코드, 데이터, 힙, 스택`)을 할당 받음으로써 프로세스가 된다.

- `코드` : 프로그램 코드
- `데이터` : 전역변수, 정적변수, 배열 등
  - 초기화 된 데이터는 data 영역에 저장
  - 초기화 되지 않은 데이터는 bss 영역에 저장
- `힙` : 동적 할당된 데이터 영역
- `스택` : 함수 호출 스택 프레임, 지역변수

운영체제는 프로세스들을 관리하기 위해 프로세스에 대한 정보가 담긴 `PCB`를 링크드리스트 형태로 관리한다.



#### IPC

#### RPC

#### RMI (Remote Method Invocation)



# 쓰레드

- CPU 이용의 기본 단위
- 쓰레드 ID, 프로그램 카운터, 레지스터 집합, 스택으로 구성된다.
- 전통적인 중량 프로세스는 하나의 제어 쓰레드를 가짐
- 같은 프로세스 내 ``` 코드, 데이터, 힙 ``` 은 공유함.
- 모든 쓰레드들은 해당 프로세스의 동일 주소공간을 공유한다.
  - 다른 스레드의 스택에 읽기나 덮어 쓰기까지 가능해버림.

### Why Thread?

1. 응답성을 향상할 수 있음.(Concurrency)
2. 멀티 프로세서 환경에서 병렬성(Parallelism)을 가능하도록 해준다. (커널수준 지원이 있어야함)
3. 프로세스간 IPC 보다 스레드간의 통신 방법이 간단함. -> 공유자원에 동시접근하므로 생기는 문제도 있음.
4. 프로세스를 create하는 작업은 overhead가 크다.
5. 프로세스간 문맥교환은 overhead가 크다.

### TCB

- 각 PCB는 TCB 리스트를 가지고 있음.

- TCB의 내용
  - 실행 상태(프로세서 레지스터, PC, SP)
  - 스케줄링 정보(상태, 우선순위, 프로세서 시간)
  - 스케줄링 큐 용 다양한 포인터
  - PCB에 대한 포인터(해당 쓰레드가 어느 프로세스에 포함되어 있는가)



### User-level thread VS Kernel-level thread

#### 사용자 스레드 (다대일 매핑)

- 스레드의 생성, 스케줄링, 관리를 커널의 개입 없이 수행함
  - 커널이 여러개의 스레드가 있다는 사실을 알리 없음
  - 사용자 공간에서 모두 이뤄지므로 생성과 관리가 빠름
- 커널 스레드가 단일 쓰레드라면 I/O 작업등에 의해 하나라도 Block되면, 사용자 스레드가 여러개 있어도 전체가 Blocked된다.
- 여러개의 사용자 스레드가 있어도, 한 순간 프로세서를 점유하는 하나의 커널 스레드로 매핑된다. (다대일 매핑)
  - 결국 커널 스레드는 하나이므로 멀티 프로세서의 병렬성을 취할 순 없음.

- 장점
  - 이식성 높음 (커널에 독립적임)
  - 커널 오버헤드 적음 (모든 작업이 유저 영역에서 수행)
  - 스케줄링 유연성 (스케줄링 정책을 해당 응용프로그램에 맞게 수정 가능)
- 단점
  - 동시성 문제 : 병렬처리 불가능, 하나의 스레드라도 block시 전체 block
  - 스레드 간 보호 어려움 (커널에서 제공하는 보호방법 사용불가)

#### 커널 스레드 (일대일 매핑)

- **커널에 의해 프로세서(core)를 할당 받을 수 있는 실행 단위**
- 생성, 스케줄링, 관리 모두 커널 공간에서 이뤄진다.
  - 여러 커널 스레드 중 한 스레드가 Block 되더라도 다른 스레드를 dispatch 할것이기 때문에 프로세스 전체가 block 되진 않는다.
- 장점
  - 각 커널 스레드가 프로세서를 할당받아 병렬수행 가능
  - 한 스레드가 block되어도 다른 스레드가 이어서 실행
- 단점
  - 커널 오버헤드 (스레드 교환에 커널이 개입하므로 사용자~커널 영역 전환 필요)
  - 프로세스 당 스레드 수 제한 (커널 스레드를 무한 생성 할 수 없음)

#### 혼합형 스레드 (다대다 매핑)

여러개의 `사용자 스레드`를 여러개의 `커널 스레드`에 유연하게 매핑함.

커널 스레드 수를 커널이 동적으로 결정 -> 커널 영역에서 병렬 처리 정도 결정

- 장점
  - `사용자 스레드`의 `동시성 문제`를 보완함.
  - `커널 스레드`의 `프로세스 당 스레드 수 제한` 문제를 해결
- 단점
  - 복잡해서 오버헤드 큼.

#### 자바 스레드

자바 스레드는 JVM에 의해 지원되므로 `유저 스레드`에도 `커널 스레드`에도 속하지 않는다.

모든 자바 프로그램은 적어도 하나의 단일 제어 스레드를 포함하고 있다.

자바 스레드가 어떻게 커널 스래드로 매핑 되는지는 JVM의 구현에 맡겨있다.

### Threading Issues

- 멀티 스레드 프로그램의 fork, exec
  - 여러 스레드 중 한 스레드가 fork를 호출한다면, 해당 스레드만 복사? 아니면 모든 스레드를 전부 복사?
  - 확실한것은 fork 후 곧바로 exec 한다면 모든 스레드를 복사하는 행위는 비효율적임.
- 스레드의 Cancellation
  - 스레드의 종료 방식
    - Asynchronous cancellation - 한 스레드가 target thread를 즉시 종료시킴
    - Deferred cancellation - target thread가 주시적으로 자신이 종료 대상인지 확인하고 스스로 종료된다.
  - 스레드가 종료 될 때 다른 스레드와 공유하는 자료구조에서 문제가 발생함.
  - 종료 스레드를 지목하기만 하고, 실제 종료는 나중에 해서 해결.
- Sinal Handling
  - 시그널이 들어오면 어떤 스레드에게 전달해야 할까?
- Thread pools
  - 웹 서버에서 요청이 들어올 때 마다 스레드를 생성하고 파기한다고 생각해보자.
    - 스레드의 잦은 생성은 overhead임.
  - 만약 어떤 피크 지점에서 동시에 들어온 요청 수가 시스템이 생성할 수 있는 스레드의 수를 넘어선다면?
  - 스레드를 미리 만들어놓고 작업들을 할당하는 방식으로 스레드 풀을 구현.
  - 스레드 풀에 가용한 스레드가 없으면 대기.
- Thread specific 데이터
  - [참고](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=deepblue28&logNo=140144079956)



# CPU 스케줄링

### 선점형 vs 비 선점형

cpu 스케줄링은 4가지 상황에서 발생할 수 있다. 

1. 한 프로세스가 실행 상태에서 대기 상태로 전환될 때 (I/O 요청, 자식 프로세스 wait)
2. 프로세스가 실행상태에서 준비 완료 상태로 전환될 때 (인터럽트)
3. 프로세스가 대기 상태에서 준비 완료 상태로 전환될 떄(I/O 완료)
4. 실행 상태이던 프로세스가 종료할 때



1,4 의 경우 반드시 스케줄링이 일어나야 한다. - `비 선점형`

2,3의 경우에도 스케줄링이 일어난다 - `선점형` (timer 등의 특수 하드웨어가 필요하다.)

`선점형` 방식으로 한 프로세스가 자료를 갱신하는 도중에 스케줄링을 수행한다면 자료의 비일관성을 초래한다.

따라서 `비 선점형` 방식이 커널 구조가 단순하다는 장점이 있지만, 실시간 컴퓨팅과 멀티 프로세싱 환경에서는 효율적이지 못하다. 

위의 비일관성 문제를 막기 위해 시작점에서 인터럽트를 무력화하고, 종료지점에서 인터럽트를 허용한다.

이러한 과정은 비용이 큰 작업이므로 fine-grained locking 사용을 최대한 늘려야 한다.



### 디스패처 

디스패처는 CPU의 제어를 단기 스케줄러가 선택한 프로세서에게 주는 모듈이다.

- 문맥을 교환함
- 사용자 모드로 전환함
- 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동(Jump)함

`Dispatch latency` : 디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는데 까지 소요되는 시간.



### 스케줄링 평가척도

- `처리율(throughput)` : 단위 시간당 완료된 프로세스의 개수

- `CPU 사용률(utilization)` : CPU 부하의 정도
- `반환시간(turnaround time)` : 프로세스의 제출 시간과 완료 시간의 차이

- `응답시간(response time)` : 요청에 대한 응답이 시작되는 데까지 걸리는 시간

- `대기시간(waiting time)` : 준비 완료 큐에서 대기하면서 보낸 시간의 합 

대부분의 경우 평균 측정 시간을 최적화 하려고 하지만 **상황에 따라** 최소 값 또는 최대 값을 최적화 하는것이 바람직할 수도 있다.



### 스케줄링 알고리즘

#### 선입선처리 (FCFS) `비선점`

어떤 프로세스가 실행 상태가 될지 선입선출로 결정됨.

각 프로세스마다 CPU 버스트 시간이 다를 때 어떤 조합의 순서로 들어오냐에 따라 `평균 대기시간`이 크게 차이난다.

모든 다른 프로세스들이 하나의 큰 프로세스가 CPU를 양도하기를 기다리는것을 `호위효과(convoy effect)` 라고 한다. 



#### 최단 작업 우선 (SJF) `비선점`

프로세서를 `가장 작은 다음 CPU 버스트`를 가진 프로세스에게 할당한다

프로세스의 전체 CPU 버스트를 기준으로 스케줄링 하는것이 아닌

**다음 CPU 버스트 길이에 의해 스케줄 된다.** 

다음 CPU 버스트 길이를 알기 어렵기 때문에 이전 CPU 버스트 길이의 지수평균을 통해 다음 값을 근사치로 구한다.

SJF는 장기 스케줄링에서 자주 사용된다.

**최소 잔여 시간 우선(Shortest Remaining Time first)** 은 SJF의 `선점형` 버전이다.

준비 완료 큐에 도착한 새로운 작업이 현재 진행중인 프로세스의 남은 CPU 버스트 타임보다 작으면 기존 작업을 새로운 작업이 선점하도록 한다.



#### 우선순위 스케줄링 `선점형` or `비선점형`

SJF 알고리즘은 우선순위 스케줄링의 특별한 경우이다.

각 프로세스는 우선순위 정보를 갖고, 가장 우선순위가 높은 프로세스에게 CPU가 할당된다.

우선순위가 같은 것들 중에서는 선입선처리(FCFS)로 처리된다.

##### `비선점형`

의 경우에는 단순히 준비완료 큐의 머리 부분에 새로운 프로세스를 넣는다.

##### `선점형` 

의 경우에는 준비 완료 큐에 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다 높다면 CPU를 선점한다.

우선순위가 높은 프로세스들이 준비 완료 큐에 계속해서 들어온다면 우선순위가 낮은 프로세스들이 CPU를 할당받지 못하는 `기아 상태` 에 이를수 있다.

`기아 상태` 를 해결하기 위해서는 오랫동안 대기하는 프로세스의 우선순위를 점진적으로 증가시키는 `에이징` 방법이 있다.



#### 라운드 로빈 (RR) `선점형`

시분할 시스템을 위해 특별히 설계된 알고리즘.

`time quantum` 을 모두 소진하면 반드시 다른 프로세스가 CPU를 선점해야 하기에 `선점형` 이다.

준비완료 큐는 원형 큐로 설계하고, 새로운 프로세스는 꼬리에 추가된다.

이제 두가지 케이스가 있다. 

1. 실행중인 프로세스의 CPU 버스트 < `time quantum`
   - 자발적으로 CPU를 반납한다.
2. 실행중인 프로세스의 CPU 버스트 >= `time quantum`
   - 해당 프로세스를 디스패치할 때 시작한 timer가 끝나고
   - 인터럽트를 보내 문맥교환이 일어나며
   - 해당 프로세스는 다시 준비완료 큐의 꼬리에 들어가게 된다.

##### RR 알고리즘에서 대기시간 상한

예를들어 5개의 프로세스와 20ms의 `time quantum` 이라고 가정할 때, 각 프로세스는 100ms마다 최대 20ms씩 할당받으며, 80ms 이상 대기하는 경우는 없다.

##### RR 알고리즘과 time quantum 크기

RR 알고리즘은 `time quantum` 크기에 매우 민감하다.

`time quantum`이 매우 **크면** RR은 FCFS와 차이가 없어진다. timer로 인한 인터럽트가 일어날 일이 없어지기 때문이다.

`time quantum`이 매우 **작으면** 사용자에게 1/n 성능의 n개의 처리기가 있는것 처럼 보일 수 있다.

하지만 문맥교환의 overhead를 고려한다면 매우 작은 `time quantum`은 `turnaround time`의 증가를 가져올 수 있다. 

RR은 평균 응답시간에 대해선 좋은 성능을 보이지만 평균 반환시간에 대해선 좋지않은 성능을 보인다.



#### 다단계 큐 스케줄링 (MLQ) `일반적으로 선점형`

프로세스의 타입(대화형, 배치처리)마다 스케줄링 요구사항이 다를 수 있다.

MLQ 에서는 준비 완료 큐를 여러 타입의 큐로 분할 하고, 각 큐는 자신만의 스케줄링 알고리즘을 가진다.

큐가 여러개라 하더라도 한 시점에선 하나의 작업이 선택되어야 하기 때문에, `큐 사이의 스케줄링` 알고리즘이 있어야한다.

일반적으로 `큐 사이의 스케줄링` 알고리즘은

1. 우선순위 선점형 스케줄링으로 구현되거나
2. 포그라운드에 80% 시간, 백그라운드에 20%의 시간을 할당하는 RR로 구현된다.



#### 다단계 피드백 큐 (MLFQ) `일반적으로 선점형`

MLFQ 에서는 MLQ와 다르게, **프로세스들이 큐 사이를 이동 할 수 있게** 한다.

여러 단개의 큐는 우선순위가 높을 수록 `time quantum` 이 작고, 낮을수록 높아진다, 가장 우선순위가 낮은 큐는 FCFS로 스케줄된다.

처음 들어오는 작업은 가장 우선순위가 높은 큐에 들어오고, CPU 버스트가 `time quantum` 보다 길어 인터럽트를 받게 되면, 한단계 낮은 우선순위의 큐로 들어가게 된다. 

여러개의 큐 중 어떤 큐에서 작업이 선택되는것은 높은 우선순위의 큐에 프로세스가 한개도 없을 때 이루어진다.

이전 작업에서 CPU 버스트가 컸던 탓에 우선순위가 한없이 낮아지고, 높은 우선순위의 큐에 프로세스가 없는 상황이 오지 않으면 `기아 상태`가 발생할 수 있다.

또한, 프로그램의 특성이 실행 중에 변화한다면(CPU 버스트 중심 -> I/O 버스트 중심) 이를 반영해주는것이 좋다.

이를 위해서 `에이징` 을 통해 다시 높은 우선순위의 큐로 이동할 수 있도록해서 우선순위를 동적으로 결정할 수 있게 한다.

이를 통해 `기아 상태` 를 예방하고, 실행 상황에 대해 유연하게 스케줄링 할 수 있는 방법을 제공한다. 

SJF 에서 CPU 버스트 를 예측하기 어려웠던 반면에 MLFQ에서는 프로세스 자신이 동적으로 CPU 중심인지, IO 중심인지를 결정하게 되며 SJF를 근사하게 된다.

##### MLFQ 를 정의하는 하이퍼 파라미터

1. 큐 수
2. 각 큐의 스케줄링 알고리즘
3. 프로세스가 어느 큐에 들어갈 것인지 정하는 방법
4. 프로세스를 높은 우선순위의 큐로 격상시키는 방법
5. 프로세스를 낮은 우선순위의 큐로 격하시키는 방법
6. 큐들간의 CPU 할당 비율

많은 변수들로 MLFQ가 정의되기 때문에 유연성이 있고, 특정 시스템에 맞게 튜닝할 수 있기에 일반적인 스케줄링 알고리즘으로 사용된다.

반면 구현하기 복잡하다는 단점이 있다.



#### Highest Response-ratio Next (HRN) `비선점형`

우선순위 스케줄링의 일종이며, 고정된 우선순위가 아닌 (대기시간 + 서비스시간)/(서비스시간) 을 우선순위로 사용한다.

기본적으로 서비스시간이 짧을수록 유리하지만, 분자에 대기시간을 넣어줌으로써 `에이징` 을 적용해, 기아상태를 예방한다.

SJF의 기아문제를 해결



# 프로세스 동기화









# 교착상태











# 메모리 관리













# 가상 메모리



















